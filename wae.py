import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.init as init
import torch.nn.functional as F
import torch.autograd as autograd
import time

import torch.backends.cudnn as cudnn
import matplotlib.pyplot as plt
from torch.optim import Adam
from torch.utils import data
from torch.nn import Conv2d, ConvTranspose2d, BatchNorm2d, LeakyReLU, ReLU, Tanh, Dropout2d
from torchvision import datasets, transforms, utils
import bottleneck as bn

from tqdm import tqdm
from torch.utils.data import DataLoader
from torch.autograd import Variable
from torchvision.datasets import MNIST
from torchvision.transforms import transforms
from torchvision.utils import save_image
from torch.optim.lr_scheduler import StepLR
import os

from itertools import chain
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
import numpy as np

torch.manual_seed(0)
os.environ["CUDA_VISIBLE_DEVICES"]="1"
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

cudnn.benchmark = True

def imq_kernel(X: torch.Tensor,
               Y: torch.Tensor,
               h_dim: int):
    batch_size = X.size(0)

    norms_x = X.pow(2).sum(1, keepdim=True)  # batch_size x 1
    prods_x = torch.mm(X, X.t())  # batch_size x batch_size
    dists_x = norms_x + norms_x.t() - 2 * prods_x

    norms_y = Y.pow(2).sum(1, keepdim=True)  # batch_size x 1
    prods_y = torch.mm(Y, Y.t())  # batch_size x batch_size
    dists_y = norms_y + norms_y.t() - 2 * prods_y

    dot_prd = torch.mm(X, Y.t())
    dists_c = norms_x + norms_y.t() - 2 * dot_prd

    stats = 0
    for scale in [.1, .2, .5, 1., 2., 5., 10.]:
        C = 2 * h_dim * 1.0 * scale
        res1 = C / (C + dists_x)
        res1 += C / (C + dists_y)

        if torch.cuda.is_available():
            res1 = (1 - torch.eye(batch_size).cuda()) * res1
        else:
            res1 = (1 - torch.eye(batch_size)) * res1

        res1 = res1.sum() / (batch_size - 1)
        res2 = C / (C + dists_c)
        res2 = res2.sum() * 2. / (batch_size)
        stats += res1 - res2

    return stats

# torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, 
# bias=True, padding_mode='zeros', device=None, dtype=None)
class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        
        self.main = nn.Sequential(
            Conv2d(NUM_CHANNELS, DIM, 4, 2, 1, bias=False), BatchNorm2d(DIM), Dropout2d(DROP), ReLU(inplace=True),
            Conv2d(DIM, DIM * 2, 4, 2, 1, bias=False), BatchNorm2d(DIM * 2), Dropout2d(DROP), ReLU(inplace=True),
            Conv2d(DIM * 2, DIM * 4, 4, 2, 1, bias=False), BatchNorm2d(DIM * 4), Dropout2d(DROP), ReLU(inplace=True),
            Conv2d(DIM * 4, DIM * 8, 4, 2, 1, bias=False), BatchNorm2d(DIM * 8), Dropout2d(DROP), ReLU(inplace=True),
            Conv2d(DIM * 8, DIM * 16, 4, 2, 1, bias=False), BatchNorm2d(DIM * 16), Dropout2d(DROP), ReLU(inplace=True),
            Conv2d(DIM * 16, DIM * 32, 4, 2, 1, bias=False), BatchNorm2d(DIM * 32), Dropout2d(DROP), ReLU(inplace=True),
            Conv2d(DIM * 32, DIM * 64, 4, 2, 1, bias=False), BatchNorm2d(DIM * 64), Dropout2d(DROP), ReLU(inplace=True),
            Conv2d(DIM * 64, DIM * 128, 4, 1, 0, bias=False), BatchNorm2d(DIM * 128), Dropout2d(DROP), ReLU(inplace=True),
            #Conv2d(DIM * 64, DIM * 128, 4, 2, 1, bias=False), BatchNorm2d(DIM * 128), ReLU(inplace=True),
            #Conv2d(DIM * 128, DIM * 128, 4, 1, 0, bias=False), BatchNorm2d(DIM * 128), ReLU(inplace=True),
        )
        self.fc = nn.Sequential(
            #nn.Linear(DIM * 64, DIM * 64), ReLU(),
            nn.Linear(DIM * 128, NLAT)
        )
        
    def forward(self, x):
        x = self.main(x)
        x = x.squeeze()
        x = self.fc(x)
        return x
    
class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()
        
        self.proj = nn.Sequential(
            nn.Linear(NLAT, DIM * 128), ReLU(),
            #nn.Linear(DIM * 64, DIM * 64), ReLU()
        )
        
        self.main = nn.Sequential(
            #ConvTranspose2d(DIM * 128, DIM * 128, 4, 1, 0, bias=False), BatchNorm2d(DIM * 128), ReLU(inplace=True),
            #ConvTranspose2d(DIM * 128, DIM * 64, 4, 2, 1, bias=False), BatchNorm2d(DIM * 64), ReLU(inplace=True),
            ConvTranspose2d(DIM * 128, DIM * 64, 4, 1, 0, bias=False), BatchNorm2d(DIM * 64), Dropout2d(DROP), ReLU(inplace=True),
            ConvTranspose2d(DIM * 64, DIM * 32, 4, 2, 1, bias=False), BatchNorm2d(DIM * 32), Dropout2d(DROP), ReLU(inplace=True),
            ConvTranspose2d(DIM * 32, DIM * 16, 4, 2, 1, bias=False), BatchNorm2d(DIM * 16), Dropout2d(DROP), ReLU(inplace=True),
            ConvTranspose2d(DIM * 16, DIM * 8, 4, 2, 1, bias=False), BatchNorm2d(DIM * 8), Dropout2d(DROP), ReLU(inplace=True),
            ConvTranspose2d(DIM * 8, DIM * 4, 4, 2, 1, bias=False), BatchNorm2d(DIM * 4), Dropout2d(DROP), ReLU(inplace=True),
            ConvTranspose2d(DIM * 4, DIM * 2, 4, 2, 1, bias=False), BatchNorm2d(DIM * 2), Dropout2d(DROP), ReLU(inplace=True),
            ConvTranspose2d(DIM * 2, DIM, 4, 2, 1, bias=False), BatchNorm2d(DIM), Dropout2d(DROP), ReLU(inplace=True),
            ConvTranspose2d(DIM, NUM_CHANNELS, 4, 2, 1, bias=False), nn.Sigmoid()
        )
        
    def forward(self, x):
        x = self.proj(x)
        x = x.view(-1, DIM * 128, 1, 1)
        x = self.main(x)
        return x

class AddGaussianNoise(object):
    def __init__(self, mean=0., std=1.):
        self.std = std
        self.mean = mean
        
    def __call__(self, tensor):
        return tensor + torch.randn(tensor.size()) * self.std + self.mean
    
    def __repr__(self):
        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)
        
def main():
    
    #svhn = datasets.ImageFolder('MalDroid_Images', transform=transform)
    #loader = data.DataLoader(svhn, BATCH_SIZE, shuffle=True, num_workers=2)
    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    
    transform_train = transforms.Compose([
        #transforms.RandomCrop(IMAGE_SIZE, padding=10),
        transforms.ToTensor(),
        #AddGaussianNoise(0, 0.1)
        ])
        
    transform_test = transforms.Compose([
        transforms.ToTensor(),
        ])
    
    train_dataset = datasets.ImageFolder('small/SplitDroid/Train', transform=transform_train)
    test_dataset = datasets.ImageFolder('small/SplitDroid/Test', transform=transform_test)
    
    train_loader = data.DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=16, drop_last=True)
    test_loader = data.DataLoader(test_dataset, BATCH_SIZE, shuffle=False, num_workers=16)

    encoder, decoder = Encoder(), Decoder()
    criterion = nn.MSELoss()

    encoder.train()
    decoder.train()

    if torch.cuda.is_available():
        encoder, decoder = encoder.cuda(), decoder.cuda()

    # Optimizers
    enc_optim = optim.Adam(encoder.parameters(), lr=LEARNING_RATE)
    dec_optim = optim.Adam(decoder.parameters(), lr=LEARNING_RATE)

    enc_scheduler = StepLR(enc_optim, step_size=5, gamma=0.5)
    dec_scheduler = StepLR(dec_optim, step_size=5, gamma=0.5)
            
    curr_iter = 0
    
    y_true = []
    x_encode = []

    encoder.eval()
    for ii, batchdata in enumerate(test_loader):
        # load data batch to device
        images, labels = batchdata
        images = images.to(device)
        y_true.append(labels.tolist())
        
        #encode images to latent vectors
        x_encode.append(encoder(images).cpu().detach().numpy().reshape(len(labels),NLAT))
    encoder.train()
    
    y_true = np.array(list(chain.from_iterable(y_true)))
    x_encode = np.array(list(chain.from_iterable(x_encode)))
    x_encode = (x_encode - np.mean(x_encode, axis=0)) / np.std(x_encode, axis=0)
    
    #Try some predicting with the encoding
    X_train , X_test, y_train, y_test = train_test_split(x_encode, y_true, test_size=0.30, random_state=42)

    clf = SVC(random_state=0, kernel='rbf').fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    
    print('Encoding SVM: %.4f' % (clf.score(X_test, y_test)))
            
            
    #while curr_iter < ITER:
    start_time = time.time()
    preds = []
    for epoch in range(100): 
        print("--------------------------")
        print("======== EPOCH %d ========" % (epoch+1))
        print("--------------------------")
        for batch_idx, (images, _) in enumerate(train_loader, 1):

            if torch.cuda.is_available():
                images = images.cuda()

            enc_optim.zero_grad()
            dec_optim.zero_grad()

            # ======== Train Generator ======== #

            batch_size = images.size()[0]

            z = encoder(images)
            x_recon = decoder(z)
            recon_loss = criterion(x_recon, images)

            # ======== MMD Kernel Loss ======== #

            z_fake = Variable(torch.randn(images.size()[0], NLAT) * SIGMA)
            if torch.cuda.is_available():
                z_fake = z_fake.cuda()

            z_real = encoder(images)

            mmd_loss = imq_kernel(z_real, z_fake, h_dim=NLAT)
            mmd_loss = mmd_loss / BATCH_SIZE

            total_loss = recon_loss + mmd_loss
            total_loss.backward()

            enc_optim.step()
            dec_optim.step()

            curr_iter += 1

            if curr_iter % 100 == 0:
                print("Iter: [%d], Reconstruction Loss: %.4f, MMD Loss %.4f, Seconds: %s" %
                      (curr_iter, recon_loss.data.item(), mmd_loss.item(), time.time() - start_time))

        if (epoch+1) % 10 == 0 or epoch == 0:
            print("======== SAVING MODELS ======== ")
            torch.save(encoder.state_dict(), 'reconst_images/encoder_%d_all.ckpt' % (epoch+1))
            torch.save(decoder.state_dict(), 'reconst_images/decoder_%d_all.ckpt' % (epoch+1))
        
        if (epoch+1) % 5 == 0 or epoch == 0: 
            y_true = []
            x_encode = []

            encoder.eval()
            for ii, batchdata in enumerate(test_loader):
                # load data batch to device
                images, labels = batchdata
                images = images.to(device)
                y_true.append(labels.tolist())
                
                #encode images to latent vectors
                x_encode.append(encoder(images).cpu().detach().numpy().reshape(len(labels),NLAT))
            encoder.train()
            
            y_true = np.array(list(chain.from_iterable(y_true)))
            x_encode = np.array(list(chain.from_iterable(x_encode)))
            x_encode = (x_encode - np.mean(x_encode, axis=0)) / np.std(x_encode, axis=0)
            
            #Try some predicting with the encoding
            X_train , X_test, y_train, y_test = train_test_split(x_encode, y_true, test_size=0.30, random_state=42)

            clf = SVC(random_state=0, kernel='rbf').fit(X_train, y_train)
            y_pred = clf.predict(X_test)
            
            print('Encoding SVM: %.4f' % (clf.score(X_test, y_test)))
            preds.append(clf.score(X_test, y_test))
            
        enc_scheduler.step()
        dec_scheduler.step()
        
    preds = np.around(np.array(preds), 4)    
    print('Final : ', preds)

# training hyperparameters
BATCH_SIZE = 64
ITER = 20000
IMAGE_SIZE = 1024
NUM_CHANNELS = 3
DIM = 16
NLAT = 470

LEARNING_RATE = 1e-4
SIGMA = 1
DROP = 0.1
              
if __name__ == "__main__":
    main()